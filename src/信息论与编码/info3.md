<!-- ---
title: 第三章 - 离散信源
date: 2022-04-16T23:30:00+08:00
categories: ["信息论"]
layout: note
article: false
--- -->

# 第三章 离散信源

## 3-1 离散信源的分类及其描述

根据时域：
- 单符号信源：信源每次只输出一个符号，可用随机变量描述信源输出的消息
- 符号序列信源：信源每次输出一个时域离散的符号序列，可用随机向量描述信源输出的消息
- 波形信源：信源每次输出时域连续的消息，可用随机过程描述信源输出的消息，采样后即为符号序列信源

根据时间和取值分布：
- 离散信源：在时间和取值上均离散，可用离散随机变量/随机向量/随机过程描述
- 连续信源：在时间或取值上连续，可用连续随机变量/随机向量/随机过程描述，采样后为信号、脉冲信号

根据平稳特性：
- 平稳：信源概率分布/密度不随时间改变
- 非平稳

根据记忆特性：
- 无记忆：信源在不同时刻发出的消息统计独立
- 有记忆（记忆长度有限的信源为马尔可夫信源）

信源编码：尽可能少的码元符号或尽可能低的数据速率来描述信源输出的消息

## 3-2 离散信源的熵

### 信息熵

**定义 3.5** 若信源发出 N 个不同符号 $x_1,x_2,\dots,x_i,\dots,x_N$ 分别代表 N 种不同消息，各符号概率为 $P_1,P_2,\dots,P_i,\dots,P_N$ 且相互统计独立，则为**单符号离散无记忆信源**

其信息熵为
$$H(X)=\sum^N_{i=1}P_iI(x_i)=-\sum^N_{i=1}P_i\operatorname{lb}P_i$$

**定义 3.6** 若信源发出的消息是由 K 个离散符号构成的符号序列，且各消息相互统计独立，则为发出符号序列消息的离散无记忆信源

**K 重符号序列信源**：每次发送都在 N 个符号里随机选 K 个（可重复）

**定义 3.7** 若单符号离散无记忆信源的信源空间为 $[X\cdot P]$，对其 K 重扩展得到符号序列 $X=X_1X_2\dots X_K$，则称扩展后的信源为离散无记忆信源 $[X\cdot P]$ 的 K 重扩展信源，扩展得到的符号序列记为 $X^K$

若 $X^K$ 彼此统计独立，则定义 3.7 与 3.6 等价，也是发出符号序列消息的离散无记忆信源

发出符号序列消息的离散无记忆信源的熵为
$$H(X^K)=KH(X)=-K\sum^N_{i=1}P_i\operatorname{lb}P_i$$

**定义 3.8** 若信源发出的消息是由 K 个离散符号构成的符号序列，且各消息相互统计相关，则为发出符号序列消息的离散有记忆信源

有记忆信源的符号序列之间的关联程度可以用转移概率描述

符号间非独立（有关联）会使得信源输出的信息量减少

**马尔可夫信源熵**：是一般信源熵的特例
$$H(X|Y)=-\sum_{XY}P(xy)\operatorname{lb}P(x|y)$$

### 时间熵

**时间熵** 单位时间内发出的平均信息量 $H_t$，单位 b/s 或 bps

## 3-3 信源的冗余度

**定理3.3**
